general:
    # Path where the logfile will be created
    #log_path: /opt/hidra/logs
    log_path: /var/log/hidra

    # Filename used for logging
    log_name: datamanager.log

    # User as which the service should be running
    username: hidrauser

    # Name with which the service should be running
    procname: hidra

    # IP/DNS name of the interface to bind to for external communication
    ext_ip: 0.0.0.0
    #ext_ip: asap3-p00

    # List of hosts allowed to connect. Options are:
    # [] - Nobody is allowed to connect
    # [<host>, <host>] - The hosts in the list are allowed to connect.
    # None - Everybody is allowed to connect.
    #whitelist: []
    whitelist: ["localhost"]
    #whitelist: None

eventdetector:
    # Type of event detector to use (options are:
    # inotifyx_events, watchdog_events, zmq_events, http_events)
    # Inotifyx is not python3 compatible,
    # see https://bugs.launchpad.net/inotifyx/+bug/1006053
    #type: inotify_events
    type: inotifyx_events
    #type: watchdog_events
    #type: http_events
    #type: hidra_events
    #type: zmq_events
    #type: sync_ewmscp_events

    inotifyx_events:
        # Directory to be monitor for changes
        # Inside this directory only the subdirectories "commissioning", "current"
        # and "local" are monitored
        # (needed if event detector is inotifyx_events or watchdog_events)
        monitored_dir: &monitored_dir /opt/hidra/data/source
        #monitored_dir: &monitored_dir /rd
        #monitored_dir: &monitored_dir /ramdisk

        # Subdirectories to be monitored and to store data to. These directory have to
        # exist when HiDRA is started and should not be removed during the run.
        # (needed if eventdetector is inotifyx_events or watchdog_events
        #  or if datafetcher is file_fetcher)
        fix_subdirs: &fix_subdirs
            - "commissioning/raw"
            - "commissioning/scratch_bl"
            - "current/raw"
            - "current/scratch_bl"
            - "local"

        # Flag describing if the subdirectories should be created if they do not exist.
        # This does not affect http_events, hidra_events, zmq_events since they do not
        # use the monitored_dir variable
        create_fix_subdirs: False

        # Event type of files (options are: IN_CLOSE_WRITE, IN_MOVED_TO, ...) and
        # the formats to be monitored, files in an other format will be be neglected
        # (needed if eventdetector is inotifyx_events or watchdog_events)
        monitored_events: &monitored_events {"IN_CLOSE_WRITE": [""]}
#        monitored_events: &monitored_events
#            IN_CLOSE_WRITE:
#                - ".tif"
#                - ".cbf"
#                - ".nxs"
#                - ".file"
#        monitored_events: &monitored_events
#            IN_CLOSE_WRITE:
#                - ".tif"
#                - ".cbf"
#                - ".nxs"
#            IN_MOVED_TO:
#                - ".log"
#        monitored events: &monitored_events
#            IN_MOVED_TO:
#                - ".tif"
#                - ".cbf"
#                - ".nxs"
#            IN_CLOSE_WRITE:
#                - ".log"
#        monitored_events: &monitored_events
#            NO_EVENT_MONITORED:
#                - ".cbf"

        # Number of events stored to look for doubles
        # (needed if eventdetector is inotifyx_events or http_events)
        #history_size: 2000
        #history_size: 5
        history_size: 0

        # Flag describing if a clean up thread which regularly checks
        # if some files were missed should be activated
        # (needed if eventdetector is inotifyx_events)
        #use_cleanup: True
        use_cleanup: False

        # Interval time (in seconds) used for clean up resp. checking of events
        # (only needed if eventdetector_type is inotifyx_events together with
        #  use_cleanup enabled or if eventdetector is watchdog_events)
        #action_time: 150
        action_time: 10

        # Time (in seconds) since last modification after which a file
        # will be seen as closed
        # (needed if eventdetector is inotifyx_events (for clean up) or
        #  watchdog_events)
        time_till_closed: 2

    watchdog_events:
        # Directory to be monitor for changes
        # Inside this directory only the subdirectories "commissioning", "current"
        # and "local" are monitored
        monitored_dir: *monitored_dir

        # Subdirectories to be monitored and to store data to. These directory have to
        # exist when HiDRA is started and should not be removed during the run.
        fix_subdirs: *fix_subdirs

        # Flag describing if the subdirectories should be created if they do not exist.
        create_fix_subdirs: False

        # Event type of files (options are: IN_CLOSE_WRITE, IN_MOVED_TO, ...) and
        # the formats to be monitored, files in an other format will be be neglected
        # (needed if eventdetector is inotifyx_events or watchdog_events)
        monitored_events: *monitored_events

        # Interval time (in seconds) used for clean up resp. checking of events
        #action_time: 150
        action_time: 10

        # Time (in seconds) since last modification after which a file
        # will be seen as closed
        time_till_closed: 2

    http_events:
        # Subdirectories to be monitored and to store data to. These directory have to
        # exist when HiDRA is started and should not be removed during the run.
        fix_subdirs: *fix_subdirs

        # Number of events stored to look for doubles
        history_size: 0
        #history_size: 2000

        # IP/DNS name of the detector
        det_ip: asap3-mon

        # API version of the detector
        det_api_version: 1.6.0

    sync_ewmscp_events:
        # Size of the ring buffer to store received events
        buffer_size: 50

        # Base directory the files are located
        monitored_dir: "/my_dir"

        # Kafka server to register for events
        kafka_server: ["asap3-events-01", "asap3-events-02"]

        # Kafka topic to register for events
        kafka_topic: "kuhnm_test"

        # Detector identifers used to distinguished from which detector a file
        # comes from. There are 2 variants:
        # - list of the detector ids as strings
        #   e.g. ["DET0", "DET1", "DET2"]
        # - list of dictionaries containing the detector id and the pattern in
        #   glob-style to look for this detector in the file name
        #   e.g. [{id: "DET0", pattern:"*DET0.nxs"},
        #         {id: "DET1", pattern:"*DET1.nxs"},
        #         {id: "DET2", pattern:"*DET0.nxs"}]
        detids: ["DET0", "DET1", "DET2"]
        # detids: # if the search pattern is not enough
        #    - id: "DET0"
        #      pattern: "*{}*.h5"
        #    - id: "DET1"
        #      pattern: "*{}*.h5"
        #    - id: "DET2"
        #      pattern: "*{}*.h5"

        # Number of detectors to synchronize
        n_detectors: 3

datafetcher:
    # Module with methods specifying how to get the data
    # (options are "file_fetcher", "zmq_fetcher", "http_fetcher")
    type: file_fetcher
    #type: http_fetcher
    #type: hidra_fetcher
    #type: zmq_fetcher
    #type: no_data_fetcher

    # Enable ZMQ pipe into storage system
    #use_data_stream: True
    use_data_stream: False

    # Fixed host and port to send the data to with highest priority
    # (only needed if use_data_stream is enabled)
    data_stream_targets: [["asap3-p00", 50100]]

    # Number of parallel data streams
    number_of_streams: 8

    # Should the files be removed from the source. Options are:
    # False - data stays on the source.
    # True - data is removed from the source after processing it.
    # stop_on_error - only supported if use_data_stream is enabled;
    #                 datamanager gets a feedback if the data writing was
    #                 successful.
    #                 When an error occurs the datamanager goes into error state
    #                 till it gets a notification that the error on the data
    #                 receiving side was handled.
    # with_confirmation - only supported if use_data_stream is enabled and
    #                     datafetcher_type is file_fetcher or http_fetcher;
    #                     data is removed from the source only after the target
    #                     sent a verification.
    #                     In case that a file could not be transfered, it is not
    #                     removed from the source. Here the datamanager does not go
    #                     in error state and new files are transfered if possible.
    #remove_data: True
    remove_data: False
    #remove_data: stop_on_error
    #remove_data: with_confirmation

    # Flag describing if the data should be stored in local_target
    #store_data: True
    store_data: False

    # Target directory to move the files into (needed if store_data is enabled)
    local_target: &local_target /opt/hidra/data/target
    #local_target: &local_target /gpfs

    file_fetcher:
        fix_subdirs: *fix_subdirs

    http_fetcher:
        # Subdirectories to be monitored and to store data to. These directory have to
        # exist when HiDRA is started and should not be removed during the run.
        fix_subdirs: *fix_subdirs

    no_data_fetcher:
        not_needed: True
